<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA 1.2 Reference//EN" "reference.dtd" [
]>
<reference id="reference_6ccef033-1155-40ae-a3b0-ca7ee7fab91c"><title>Get List of Assets</title><prolog><author>Linda Castellani</author></prolog><refbody><section>
            <p>This API returns a list of assets deployed within a bounding box (bbox) that you define with GPS coordinates.</p>
        </section><section>
            <table id="table_9cfacfb7-0b32-44c4-8730-549d1b8af8c1" frame="all" rowsep="1" colsep="1"><tgroup cols="2"><colspec colwidth="1*" colnum="1" colname="c1"/><colspec colwidth="3.08*" colnum="2" colname="c2"/><tbody><row><entry><b>METHOD</b></entry><entry>GET</entry></row><row><entry><b>Request URI</b></entry><entry>{{metadataurl}}/v2/assets/search?bbox=&lt;long,lat>&amp;page=&lt;int>&amp;size=&lt;int>&amp;q=assetType:&lt;assetType1>&amp;eventType=&lt;eventType1>&amp;mediaType=&lt;mediaType1></entry></row><row><entry><b>Sample Request URI</b></entry><entry>{{metadataurl}}/assets/search?bbox=32.715675:-117.161230,32.708498:-117.151681&amp;page=0&amp;size=50&amp;q=assetType:CAMERA&amp;eventType=PKIN</entry></row></tbody></tgroup></table>
        </section><section>
            <title>Query Parameters</title>
            <table id="table_953eead5-e3ce-4d1f-9479-b163f9255f7c" frame="all" rowsep="1" colsep="1"><tgroup cols="4"><colspec colwidth="1.07*" colnum="1" colname="c1"/><colspec colwidth="3.26*" colnum="2" colname="c2"/><colspec colwidth="1*" colnum="3" colname="c3"/><colspec colwidth="3.34*" colnum="4" colname="c4"/><thead><row><entry>Parameter</entry><entry>Description</entry><entry>Required?</entry><entry>Filter Values</entry></row></thead><tbody><row><entry>bbox</entry><entry>The bounded area for your search, identified by GPS coordinates.</entry><entry>Cities: Yes<p>Enterprises: No</p></entry><!----><entry><b>bbox=x1:y1, x2:y2 </b><p>Replace x1:y1, x2:y2 with GPS coordinates, similar to the following:</p><p>32.715675:-117.161230,32.708498:-117.151681</p><p>You can use Google Maps to obtain the latitude and longitude. To locate GPS coordinates for the area and identify the boundaries, place the cursor in the upper left location of the area, then right-click and select <b>Whatâ€™s here?</b> to obtain the first set of coordinates. Right-click on the lower-right location and repeat this procedure to obtain the second set of coordinates.</p><p><image id="image_f49ab071-eb85-451c-b7a3-2469856537cc" href="i_bbox_graphic_small.png"/></p></entry></row><row><entry>q</entry><entry>Identifies a "type" query.</entry><entry>No</entry><entry>Query to search by assetType, mediaType, or eventTypes.</entry></row><row><entry>assetType</entry><entry>Filter by type of asset.<note>CAMERA is the only sensor that will generate eventType and mediaType. </note></entry><entry>No</entry><entry>Insert one of the following enumeration codes to filter by a specific asset type.<dl><dlentry><dt>NODE</dt><dd>Parent asset. </dd><dd>When you filter by NODE and a bounding box, you receive a list of devices attached to each node within the boundaries, such as a camera or microphone.</dd></dlentry><dlentry><dt>CAMERA</dt><dd>If you filter by CAMERA, you receive a list of all cameras installed within the bounding box.</dd></dlentry><dlentry><dt>MIC</dt><dd>If you filter by MIC, you receive a list of all audio devices installed within the boundaries.</dd></dlentry><dlentry><dt>ENV</dt><dd>If you filter by ENV, you receive a list of all environmental sensors installed within the boundaries.</dd></dlentry><dlentry><dt>OTHERS</dt><dd>If you filter by OTHERS, you receive a list of non-standard or unknown devices.</dd></dlentry></dl></entry></row><row><entry>mediaType</entry><entry>Filter by type of media. <p>
                  <note>Get Media only works when you have access to Situational Awareness.</note>
                </p></entry><entry>No</entry><entry>Insert one of the following enumeration codes for a specific media type.<dl><dlentry><dt>IMAGE</dt><dd>If you filter by IMAGE, you receive a list of images in JPG, PNG, or GIF formats.</dd><dd>Depending on the position of the camera, it will return the best resolution image available: either 320x240 for black and white or 1920x1080 for color.</dd></dlentry><dlentry><dt>VIDEO</dt><dd>If you filter by VIDEO, you receive a list of videos in H.264 format.</dd><dd>By default, the video length is 1 minute. You can use VLC player to open the video.</dd></dlentry><dlentry><dt>AUDIO</dt><dd>If you filter by AUDIO, you receive a list of audio files in MP3 or WAV format.  This is not supported in v2.</dd></dlentry><dlentry><dt>OTHERS</dt><dd>If you filtered by OTHERS, you receive a list of non-standard formats.</dd></dlentry></dl></entry></row><row><entry>eventTypes</entry><entry>Filter by type of event.</entry><entry>No</entry><entry>Insert one of the following enumeration codes for a specific event type.<dl><dlentry><dt>PKIN</dt><dd>If you filter by PKIN, you receive a list of vehicles (identified by object-id) entering parking areas within the boundaries.</dd></dlentry><dlentry><dt>PKOUT</dt><dd>If you filter by PKOUT you receive a list of vehicles (identified by object-id) exiting parking areas within the boundaries.</dd></dlentry><dlentry><dt>PEDEVT</dt><dd>If you filter by PEDEVT, you receive a list of pedestrians (identified by object-id) exiting monitored areas with within the boundaries.</dd></dlentry><dlentry><dt>TFEVT</dt><dd>If you filter by TFEVT, you receive a list of traffic flow data.</dd></dlentry><dlentry><dt>ENCHG</dt><dd>If you filter by ENCHG, you receive a list of changed environmental conditions, such as temperature.</dd></dlentry><dlentry><dt>LIGHT_LEVEL</dt><dd>If you filter by LIGHT_LEVEL, you receive a list of assets that report illuminance sensor events within the specified bounded area.</dd></dlentry><dlentry><dt>OCCUPANCY</dt><dd>If you filter by OCCUPANCY, you receive a list of assets that report occupancy sensor events within the specified bounded area.</dd></dlentry><dlentry><dt>TEMP</dt><dd>If you filter by TEMP, you receive a list of assets that report temperature sensor events within the specified bounded area.</dd></dlentry></dl></entry></row><row><entry>size</entry><entry>Maximum number of records to return per page; if none specified, the default value of 2 is used automatically.</entry><entry>No</entry><entry>Numerical value, such as 20.</entry></row><row><entry>page</entry><entry>Indicates the page number; default is 0. </entry><entry>No</entry><entry>Numerical value, such as 1.</entry></row></tbody></tgroup></table>
        </section><section>
            <title>Response Parameters</title>
            <table id="table_b17ad35e-4823-4112-8893-3e49050caaa4" frame="all" rowsep="1" colsep="1"><tgroup cols="3"><colspec colwidth="1.45*" colnum="1" colname="c1"/><colspec colwidth="1.05*" colnum="2" colname="c2"/><colspec colwidth="4.75*" colnum="3" colname="c4"/><thead><row><entry>Parameter</entry><entry>Data Type</entry><entry>Description</entry></row></thead><tbody><row><entry><parmname>assetUid</parmname></entry><entry>String</entry><entry>A unique identifier established by a customer or external resource. For example, CAMERA-STG-HYP1042-CAM-L to identify a camera.</entry></row><row><entry><parmname>parentAssetUid</parmname></entry><entry>string</entry><entry>A unique identifier assigned to the asset at the top of a hierarchical set of assets, in other words, the parent of a child asset. For example, a node is a parent asset, comprising child assets such as cameras or microphones.</entry></row><row><entry><parmname>eventTypes</parmname></entry><entry>String</entry><entry>The event type that was recorded. In the sample response data, the camera on the specified node is collecting data on parking instances (vehicle in, vehicle out) and traffic flow in the parking area.<dl><dlentry><dt>PKIN</dt><dd>If you filtered by PKIN, you receive a list of vehicles (identified by object-id) entering parking areas within the boundaries.</dd></dlentry><dlentry><dt>PKOUT</dt><dd>If you filtered by PKOUT you receive a list of vehicles (identified by object-id) exiting parking areas within the boundaries.</dd></dlentry><dlentry><dt>PEDEVT</dt><dd>If you filtered by PEDEVT, you receive a list of pedestrians (identified by object-id) exiting monitored areas with within the boundaries.</dd></dlentry><dlentry><dt>TFEVT</dt><dd>If you filtered by TFEVT, you receive a list of traffic flow information.</dd></dlentry><dlentry><dt>ENCHG</dt><dd>If you filter by ENCHG, you receive a list of changed environmental conditions, such as temperature.</dd></dlentry><dlentry><dt>LIGHT_LEVEL</dt><dd>If you filtered by LIGHT_LEVEL, you receive a list of assets that report illuminance sensor events within the specified bounded area.</dd></dlentry><dlentry><dt>OCCUPANCY</dt><dd>If you filtered by OCCUPANCY, you receive a list of assets that report occupancy sensor events within the specified bounded area.</dd></dlentry><dlentry><dt>TEMP</dt><dd>If you filtered by TEMP, you receive a list of assets that report temperature sensor events within the specified bounded area.</dd></dlentry></dl></entry></row><row><entry><parmname>mediaType</parmname></entry><entry>String</entry><entry>Media output. In the sample response data, the camera on the specified node is collecting video to record when vehicles enter and exit a parking space.<dl><dlentry><dt>IMAGE</dt><dd>If you filter by IMAGE, you receive a list of images in JPG, PNG, or GIF formats.</dd><dd>Depending on the position of the camera, it will return the best resolution image available: either 320x240 for black and white or 1920x1080 for color.</dd></dlentry><dlentry><dt>VIDEO</dt><dd>If you filter by VIDEO, you receive a list of videos in H.264 format.</dd><dd>By default, the video length is 1 minute. You can use VLC player to open the video.</dd></dlentry><dlentry><dt>AUDIO</dt><dd>If you filtered by AUDIO, you receive a list of audio files in MP3 or WAV format.</dd></dlentry><dlentry><dt>OTHERS</dt><dd>If you filtered by OTHERS, you receive a list of non-standard formats.</dd></dlentry></dl></entry></row><row><entry><parmname>assetType</parmname></entry><entry>String</entry><entry>Type of asset that is recording the events.<dl><dlentry><dt>NODE</dt><dd>Parent asset.</dd></dlentry><dlentry><dt>CAMERA</dt><dd>If you filtered by CAMERA, you receive a list of all cameras installed within the bounding box.</dd></dlentry><dlentry><dt>MIC</dt><dd>If you filtered by MIC, you receive a list of all audio devices installed within the boundaries.</dd></dlentry><dlentry><dt>ENV</dt><dd>If you filtered by ENV, you receive a list of all environmental sensors installed within the boundaries.</dd></dlentry><dlentry><dt>OTHERS</dt><dd>If you filtered by OTHERS, you receive a list of non-standard or unknown devices.</dd></dlentry></dl></entry></row><row><entry>
                                <parmname>coordinates</parmname></entry><entry>String</entry><entry>The GPS coordinates (latitude, longitude) for the referenced asset (identified by assetUid), such as <b>32.711653,-117.157314</b> to identify where the camera is installed. </entry></row></tbody></tgroup></table>
        </section><section>
      <title>Sample Response</title>
      <codeblock>{
  "content": [
    {
      "assetUid": "STG-HYP1087-170",
      "parentAssetUid": "POLE-HYP1087-43",
      "eventTypes": [
        "TFEVT",
        "PKIN",
        "PEDEVT",
        "PKOUT"
      ],
      "mediaType": "IMAGE",
      "assetType": "CAMERA",
      "coordinates": "30.328126000000001:-81.6596200000000039"
    },
  ],
  "last": true,
  "totalElements": 6,
  "totalPages": 1,
  "numberOfElements": 6,
  "first": true,
  "sort": null,
  "size": 50,
  "number": 0
}</codeblock>
    </section></refbody></reference>